{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook\n",
    "\n",
    "- We contruct a combination ranking based on the top 1000 terms and ranks\n",
    "    - For now, we are going to select top terms (or nearest terms) from across all keyterm lists after deduplication of course\n",
    "\n",
    "- We store the phrase2idx and phrase2vector mapping as a pickle\n",
    "\n",
    "- We construct and save a nearest neighbor object to help find the closest phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'phrase_extraction' from '/home/nino/GetGabby/notebooks/phrase_extraction.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(phrase_filters)\n",
    "importlib.reload(phrase_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/test_data.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/miniconda3/envs/gabby-env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import phrase_extraction\n",
    "import phrase_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = phrase_extraction.featurization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>review_date</th>\n",
       "      <th>will_recommend</th>\n",
       "      <th>contents</th>\n",
       "      <th>review_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simply the best</td>\n",
       "      <td>Outstanding picture color and brightness. I ch...</td>\n",
       "      <td>April 8, 2022</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Simply the best. Outstanding picture color and...</td>\n",
       "      <td>[simply, the, best, ., outstanding, picture, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65\" Bravia XR A90J Smart TV &amp; JBL 501 Soundbar</td>\n",
       "      <td>Excellent installation job of my 65\" Sony XR A...</td>\n",
       "      <td>October 30, 2021</td>\n",
       "      <td>Yes</td>\n",
       "      <td>65\" Bravia XR A90J Smart TV &amp; JBL 501 Soundbar...</td>\n",
       "      <td>[65, \", bravia, xr, a90j, smart, tv, &amp;, jbl, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Best of All</td>\n",
       "      <td>Best color of any that TV I have see. Even the...</td>\n",
       "      <td>December 12, 2021</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The Best of All. Best color of any that TV I h...</td>\n",
       "      <td>[the, best, of, all, ., best, color, of, any, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A JAW DROPPING, STUNNING MASTERPIECE!</td>\n",
       "      <td>I've owned several oleds from LG and Sony and ...</td>\n",
       "      <td>May 11, 2021</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A JAW DROPPING, STUNNING MASTERPIECE!. I've ow...</td>\n",
       "      <td>[a, jaw, dropping, ,, stunning, masterpiece, !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely AMAZING!</td>\n",
       "      <td>Ive been an Oled fan since they became availab...</td>\n",
       "      <td>April 22, 2022</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Absolutely AMAZING!. Ive been an Oled fan sinc...</td>\n",
       "      <td>[absolutely, amazing, !, ., i, ve, been, an, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                                 Simply the best   \n",
       "1  65\" Bravia XR A90J Smart TV & JBL 501 Soundbar   \n",
       "2                                 The Best of All   \n",
       "3           A JAW DROPPING, STUNNING MASTERPIECE!   \n",
       "4                             Absolutely AMAZING!   \n",
       "\n",
       "                                              review        review_date  \\\n",
       "0  Outstanding picture color and brightness. I ch...      April 8, 2022   \n",
       "1  Excellent installation job of my 65\" Sony XR A...   October 30, 2021   \n",
       "2  Best color of any that TV I have see. Even the...  December 12, 2021   \n",
       "3  I've owned several oleds from LG and Sony and ...       May 11, 2021   \n",
       "4  Ive been an Oled fan since they became availab...     April 22, 2022   \n",
       "\n",
       "  will_recommend                                           contents  \\\n",
       "0            Yes  Simply the best. Outstanding picture color and...   \n",
       "1            Yes  65\" Bravia XR A90J Smart TV & JBL 501 Soundbar...   \n",
       "2            Yes  The Best of All. Best color of any that TV I h...   \n",
       "3            Yes  A JAW DROPPING, STUNNING MASTERPIECE!. I've ow...   \n",
       "4            Yes  Absolutely AMAZING!. Ive been an Oled fan sinc...   \n",
       "\n",
       "                                       review_tokens  \n",
       "0  [simply, the, best, ., outstanding, picture, c...  \n",
       "1  [65, \", bravia, xr, a90j, smart, tv, &, jbl, 5...  \n",
       "2  [the, best, of, all, ., best, color, of, any, ...  \n",
       "3  [a, jaw, dropping, ,, stunning, masterpiece, !...  \n",
       "4  [absolutely, amazing, !, ., i, ve, been, an, o...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get the keyword lists from each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_mi = phrase_extraction.keyterm_extraction_mutual_information(df)\n",
    "phrases_tfidf = phrase_extraction.keyterm_extraction_tfidf(df)\n",
    "phrases_freq = phrase_extraction.keyterm_extraction_frequency(df)\n",
    "phrases_yake = phrase_extraction.keyterm_extraction_yake(df)\n",
    "phrases_trank = phrase_extraction.keyterm_extraction_textrank(df)\n",
    "phrases_scake = phrase_extraction.keyterm_extraction_scake(df)\n",
    "phrases_ent_nc = phrase_extraction.keyterm_extraction_entities_and_noun_chunks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets run the filters selectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_model_terms = ['Sony', 'LG', 'Bravia', 'a09','xr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4388, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_mi = phrase_filters.filter_phrases_containing_stopwords(phrases_mi)\n",
    "phrases_mi = phrase_filters.filter_phrases_containing_punctuation(phrases_mi)\n",
    "phrases_mi = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_mi, brand_model_terms)\n",
    "phrases_mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6209, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_tfidf = phrase_filters.filter_phrases_containing_stopwords(phrases_tfidf)\n",
    "phrases_tfidf = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_tfidf, brand_model_terms)\n",
    "phrases_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6209, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_freq = phrase_filters.filter_phrases_containing_stopwords(phrases_freq)\n",
    "phrases_freq = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_freq, brand_model_terms)\n",
    "phrases_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1424, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_ent_nc = phrase_filters.filter_phrases_containing_stopwords(phrases_ent_nc)\n",
    "phrases_ent_nc = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_ent_nc, brand_model_terms)\n",
    "phrases_ent_nc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    }
   ],
   "source": [
    "phrases_scake = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_scake, brand_model_terms)\n",
    "phrases_yake = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_yake, brand_model_terms)\n",
    "phrases_trank = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_trank, brand_model_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(884, 2), (958, 2), (881, 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pdf.shape for pdf in [phrases_scake, phrases_yake, phrases_trank]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating indexes and vector stores for phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top_keyterms_data_structures(df, save_file_prefix, topk=1000):\n",
    "    topkdf = df.sort_values('score', ascending=False).head(topk)\n",
    "    phrase2idx = dict(zip(topkdf['phrase'].tolist(), range(topkdf.shape[0])))\n",
    "    phrase2vector = dict(zip(topkdf['phrase'].tolist(), topkdf['phrase'].apply(lambda x: nlp(x).vector)))\n",
    "\n",
    "    with open(save_file_prefix + '_phrase2idx.pkl', 'wb') as outf:\n",
    "        pickle.dump(phrase2idx, outf)\n",
    "\n",
    "    with open(save_file_prefix + '_phrase2vector.pkl', 'wb') as outf:\n",
    "        pickle.dump(phrase2vector, outf)\n",
    "\n",
    "    topkdf.to_pickle(save_file_prefix + '_df.pkl')\n",
    "    \n",
    "    return phrase2idx, phrase2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, __ = generate_top_keyterms_data_structures(phrases_mi, 'phrases_mi')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_tfidf, 'phrases_tfidf')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_freq, 'phrases_freq')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_yake, 'phrases_yake')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_scake, 'phrases_scake')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_trank, 'phrases_trank')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_ent_nc, 'phrases_ent_nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighor searches for keyterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_mi_NN = NearestNeighbors(n_neighbors=5).fit(np.vstack(list(phrases_mi2vec.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_tfidf_NN = NearestNeighbors(n_neighbors=5).fit(np.vstack(list(phrases_tfidf2vec.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 k</td>\n",
       "      <td>29.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dolby vision</td>\n",
       "      <td>15.810277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>picture quality</td>\n",
       "      <td>13.313034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>itv hub</td>\n",
       "      <td>7.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>master series</td>\n",
       "      <td>7.062069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            phrase      score\n",
       "0              4 k  29.823529\n",
       "2     dolby vision  15.810277\n",
       "3  picture quality  13.313034\n",
       "7          itv hub   7.363636\n",
       "8    master series   7.062069"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvec = phrases_mi2vec['master series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[706, 568, 529, 638, 671]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists, idxs = phrase_tfidf_NN.kneighbors(qvec.reshape((1, -1)))\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2phrases_tfidf = {v:k for k, v in phrase_tfidf2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inch master series',\n",
       " 'resolution netflix',\n",
       " 'netflix picture',\n",
       " 'panasonic plasma',\n",
       " 'service award']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2phrases_tfidf[i] for i in idxs.reshape(-1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build main data struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: load data structs\n",
    "algo_names = ['phrases_mi', 'phrases_tfidf', 'phrases_freq', 'phrases_yake', 'phrases_scake', 'phrases_trank', 'phrases_ent_nc']\n",
    "\n",
    "keyterms = {}\n",
    "\n",
    "for algo in algo_names:\n",
    "    keyterms[algo] = {}\n",
    "    \n",
    "    with open(algo + '_phrase2idx.pkl', 'rb') as infile:\n",
    "        keyterms[algo]['phrase2idx'] = pickle.load(infile)\n",
    "        keyterms[algo]['idx2phrase'] = {v:k for k, v in keyterms[algo]['phrase2idx'].items()}\n",
    "    \n",
    "    with open(algo + '_phrase2vector.pkl', 'rb') as infile:\n",
    "        keyterms[algo]['phrase2vector'] = pickle.load(infile)\n",
    "\n",
    "    keyterms[algo]['df'] = pd.read_pickle(algo + '_df.pkl')\n",
    "    \n",
    "    keyterms[algo]['NN'] = NearestNeighbors(n_neighbors=5).fit(np.vstack(list(keyterms[algo]['phrase2vector'].values())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.       , 3.44608  , 4.062665 , 4.1328115, 4.1355934]],\n",
       "       dtype=float32),\n",
       " array([[159, 914, 648, 758, 175]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyterms['phrases_ent_nc']['NN'].kneighbors(qvec.reshape((1, -1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(11235813)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_terms(keyterms, topn=10):\n",
    "    seed_terms = set()\n",
    "    for algo in algo_names:\n",
    "        _terms = keyterms[algo]['df'].head(topn)['phrase'].tolist()\n",
    "        if any(['imagine' in t for t in _terms]):\n",
    "            print(algo)\n",
    "        seed_terms.update(_terms)\n",
    "    print(len(seed_terms))\n",
    "    return np.random.choice(list(seed_terms), topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>best outstanding</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28678</th>\n",
       "      <td>water imagine needing</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28777</th>\n",
       "      <td>home theatre system</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28776</th>\n",
       "      <td>existing home theatre</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28762</th>\n",
       "      <td>physical appletv</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28751</th>\n",
       "      <td>streaming platforms</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28749</th>\n",
       "      <td>major uk</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28736</th>\n",
       "      <td>system picture</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28735</th>\n",
       "      <td>home theatre</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28734</th>\n",
       "      <td>existing home</td>\n",
       "      <td>6.138735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      phrase     score\n",
       "2           best outstanding  6.138735\n",
       "28678  water imagine needing  6.138735\n",
       "28777    home theatre system  6.138735\n",
       "28776  existing home theatre  6.138735\n",
       "28762       physical appletv  6.138735\n",
       "28751    streaming platforms  6.138735\n",
       "28749               major uk  6.138735\n",
       "28736         system picture  6.138735\n",
       "28735           home theatre  6.138735\n",
       "28734          existing home  6.138735"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_tfidf.sort_values('score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phrases_tfidf\n",
      "119\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['existing home', 'home theatre', 'year old', 'sound quality',\n",
       "       'luck', 'good hdr tv', 'tone mapping', 'all4', 'black levels',\n",
       "       'tone mapping', 'good hdr image', 'home theatre', 'shopping',\n",
       "       'blown away', 'key', 'amazing tv set', 'youview', 'bbc iplayer',\n",
       "       'old oled tv', 'good tv operating system'], dtype='<U33')"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_top_terms(keyterms, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_close_terms(query, keyterms, topn=10):\n",
    "    qvec = nlp(query).vector.reshape(1, -1)\n",
    "    close_terms = set()\n",
    "    for algo in algo_names:\n",
    "        dists, idxs = keyterms[algo]['NN'].kneighbors(qvec)\n",
    "        _terms = [keyterms[algo]['idx2phrase'][i] for i in idxs.reshape(-1)]\n",
    "        close_terms.update(_terms)\n",
    "    return np.random.choice(list(close_terms), topn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['football season', 'movie theater', 'tv screen', 'tv rock',\n",
       "       'quality game play', 'market product', 'tv buyer', 'home internet',\n",
       "       'home system', 'home theater'], dtype='<U23')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_close_terms('home theatre', keyterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>sound</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>google tv</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>picture</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>netflix</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>tv</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>4k hdr</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>combination</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>justice</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>20/20 vision</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4k television set</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 phrase  score\n",
       "294               sound     39\n",
       "295           google tv     35\n",
       "555             picture     33\n",
       "1054            netflix     30\n",
       "333                  tv     26\n",
       "...                 ...    ...\n",
       "285              4k hdr      1\n",
       "335         combination      1\n",
       "330             justice      1\n",
       "327        20/20 vision      1\n",
       "323   4k television set      1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyterms['phrases_ent_nc']['df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f54399830bbbc072644b83a18bcca8782c4daf93d62544fb85b1f9757394fef"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gabby-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
