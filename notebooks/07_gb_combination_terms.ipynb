{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In this notebook\n",
    "\n",
    "- We contruct a combination ranking based on the top 1000 terms and ranks\n",
    "    - For now, we are going to select top terms (or nearest terms) from across all keyterm lists after deduplication of course\n",
    "\n",
    "- We store the phrase2idx and phrase2vector mapping as a pickle\n",
    "\n",
    "- We construct and save a nearest neighbor object to help find the closest phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'phrase_extraction' from '/home/nino/GetGabby/notebooks/phrase_extraction.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "importlib.reload(phrase_filters)\n",
    "importlib.reload(phrase_extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"../data/test_data.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/miniconda3/envs/gabby-env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import phrase_extraction\n",
    "import phrase_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = phrase_extraction.featurization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>review_date</th>\n",
       "      <th>will_recommend</th>\n",
       "      <th>contents</th>\n",
       "      <th>review_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simply the best</td>\n",
       "      <td>Outstanding picture color and brightness. I ch...</td>\n",
       "      <td>April 8, 2022</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Simply the best. Outstanding picture color and...</td>\n",
       "      <td>[simply, the, best, ., outstanding, picture, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65\" Bravia XR A90J Smart TV &amp; JBL 501 Soundbar</td>\n",
       "      <td>Excellent installation job of my 65\" Sony XR A...</td>\n",
       "      <td>October 30, 2021</td>\n",
       "      <td>Yes</td>\n",
       "      <td>65\" Bravia XR A90J Smart TV &amp; JBL 501 Soundbar...</td>\n",
       "      <td>[65, \", bravia, xr, a90j, smart, tv, &amp;, jbl, 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Best of All</td>\n",
       "      <td>Best color of any that TV I have see. Even the...</td>\n",
       "      <td>December 12, 2021</td>\n",
       "      <td>Yes</td>\n",
       "      <td>The Best of All. Best color of any that TV I h...</td>\n",
       "      <td>[the, best, of, all, ., best, color, of, any, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A JAW DROPPING, STUNNING MASTERPIECE!</td>\n",
       "      <td>I've owned several oleds from LG and Sony and ...</td>\n",
       "      <td>May 11, 2021</td>\n",
       "      <td>Yes</td>\n",
       "      <td>A JAW DROPPING, STUNNING MASTERPIECE!. I've ow...</td>\n",
       "      <td>[a, jaw, dropping, ,, stunning, masterpiece, !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely AMAZING!</td>\n",
       "      <td>Ive been an Oled fan since they became availab...</td>\n",
       "      <td>April 22, 2022</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Absolutely AMAZING!. Ive been an Oled fan sinc...</td>\n",
       "      <td>[absolutely, amazing, !, ., i, ve, been, an, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            title  \\\n",
       "0                                 Simply the best   \n",
       "1  65\" Bravia XR A90J Smart TV & JBL 501 Soundbar   \n",
       "2                                 The Best of All   \n",
       "3           A JAW DROPPING, STUNNING MASTERPIECE!   \n",
       "4                             Absolutely AMAZING!   \n",
       "\n",
       "                                              review        review_date  \\\n",
       "0  Outstanding picture color and brightness. I ch...      April 8, 2022   \n",
       "1  Excellent installation job of my 65\" Sony XR A...   October 30, 2021   \n",
       "2  Best color of any that TV I have see. Even the...  December 12, 2021   \n",
       "3  I've owned several oleds from LG and Sony and ...       May 11, 2021   \n",
       "4  Ive been an Oled fan since they became availab...     April 22, 2022   \n",
       "\n",
       "  will_recommend                                           contents  \\\n",
       "0            Yes  Simply the best. Outstanding picture color and...   \n",
       "1            Yes  65\" Bravia XR A90J Smart TV & JBL 501 Soundbar...   \n",
       "2            Yes  The Best of All. Best color of any that TV I h...   \n",
       "3            Yes  A JAW DROPPING, STUNNING MASTERPIECE!. I've ow...   \n",
       "4            Yes  Absolutely AMAZING!. Ive been an Oled fan sinc...   \n",
       "\n",
       "                                       review_tokens  \n",
       "0  [simply, the, best, ., outstanding, picture, c...  \n",
       "1  [65, \", bravia, xr, a90j, smart, tv, &, jbl, 5...  \n",
       "2  [the, best, of, all, ., best, color, of, any, ...  \n",
       "3  [a, jaw, dropping, ,, stunning, masterpiece, !...  \n",
       "4  [absolutely, amazing, !, ., i, ve, been, an, o...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get the keyword lists from each algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_mi = phrase_extraction.keyterm_extraction_mutual_information(df)\n",
    "phrases_tfidf = phrase_extraction.keyterm_extraction_tfidf(df)\n",
    "phrases_freq = phrase_extraction.keyterm_extraction_frequency(df)\n",
    "phrases_yake = phrase_extraction.keyterm_extraction_yake(df)\n",
    "phrases_trank = phrase_extraction.keyterm_extraction_textrank(df)\n",
    "phrases_scake = phrase_extraction.keyterm_extraction_scake(df)\n",
    "phrases_ent_nc = phrase_extraction.keyterm_extraction_entities_and_noun_chunks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets run the filters selectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_model_terms = ['Sony', 'LG', 'Bravia', 'a09','xr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4388, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_mi = phrase_filters.filter_phrases_containing_stopwords(phrases_mi)\n",
    "phrases_mi = phrase_filters.filter_phrases_containing_punctuation(phrases_mi)\n",
    "phrases_mi = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_mi, brand_model_terms)\n",
    "phrases_mi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6209, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_tfidf = phrase_filters.filter_phrases_containing_stopwords(phrases_tfidf)\n",
    "phrases_tfidf = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_tfidf, brand_model_terms)\n",
    "phrases_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6209, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_freq = phrase_filters.filter_phrases_containing_stopwords(phrases_freq)\n",
    "phrases_freq = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_freq, brand_model_terms)\n",
    "phrases_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1424, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_ent_nc = phrase_filters.filter_phrases_containing_stopwords(phrases_ent_nc)\n",
    "phrases_ent_nc = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_ent_nc, brand_model_terms)\n",
    "phrases_ent_nc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nino/GetGabby/notebooks/phrase_filters.py:49: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  return df[ ~df['phrase'].str.contains(pattern, case=False)]\n"
     ]
    }
   ],
   "source": [
    "phrases_scake = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_scake, brand_model_terms)\n",
    "phrases_yake = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_yake, brand_model_terms)\n",
    "phrases_trank = phrase_filters.filter_phrases_containing_brand_model_terms(phrases_trank, brand_model_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(884, 2), (958, 2), (881, 2)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[pdf.shape for pdf in [phrases_scake, phrases_yake, phrases_trank]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating indexes and vector stores for phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_top_keyterms_data_structures(df, save_file_prefix, topk=1000):\n",
    "    topkdf = df.sort_values('score', ascending=False).head(topk)\n",
    "    phrase2idx = dict(zip(topkdf['phrase'].tolist(), range(topkdf.shape[0])))\n",
    "    phrase2vector = dict(zip(topkdf['phrase'].tolist(), topkdf['phrase'].apply(lambda x: nlp(x).vector)))\n",
    "\n",
    "    with open(save_file_prefix + '_phrase2idx.pkl', 'wb') as outf:\n",
    "        pickle.dump(phrase2idx, outf)\n",
    "\n",
    "    with open(save_file_prefix + '_phrase2vector.pkl', 'wb') as outf:\n",
    "        pickle.dump(phrase2vector, outf)\n",
    "\n",
    "    topkdf.to_pickle(save_file_prefix + '_df.pkl')\n",
    "    \n",
    "    return phrase2idx, phrase2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_mi2idx, phrases_mi2vec = generate_top_keyterms_data_structures(phrases_mi, 'phrase_mi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_tfidf2idx, phrases_tfidf2vec = generate_top_keyterms_data_structures(phrases_tfidf, 'phrase_tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, __ = generate_top_keyterms_data_structures(phrases_freq, 'phrases_freq')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_yake, 'phrases_yake')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_scake, 'phrases_scake')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_trank, 'phrases_trank')\n",
    "_, __ = generate_top_keyterms_data_structures(phrases_ent_nc, 'phrases_ent_nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighor searches for keyterms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_mi_NN = NearestNeighbors(n_neighbors=5).fit(np.vstack(list(phrases_mi2vec.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_tfidf_NN = NearestNeighbors(n_neighbors=5).fit(np.vstack(list(phrases_tfidf2vec.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 k</td>\n",
       "      <td>29.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dolby vision</td>\n",
       "      <td>15.810277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>picture quality</td>\n",
       "      <td>13.313034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>itv hub</td>\n",
       "      <td>7.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>master series</td>\n",
       "      <td>7.062069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            phrase      score\n",
       "0              4 k  29.823529\n",
       "2     dolby vision  15.810277\n",
       "3  picture quality  13.313034\n",
       "7          itv hub   7.363636\n",
       "8    master series   7.062069"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_mi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "qvec = phrases_mi2vec['master series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qvec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[706, 568, 529, 638, 671]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists, idxs = phrase_tfidf_NN.kneighbors(qvec.reshape((1, -1)))\n",
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2phrases_tfidf = {v:k for k, v in phrase_tfidf2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['inch master series',\n",
       " 'resolution netflix',\n",
       " 'netflix picture',\n",
       " 'panasonic plasma',\n",
       " 'service award']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[idx2phrases_tfidf[i] for i in idxs.reshape(-1)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build main data struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: load data structs\n",
    "algo_dfs = [phrases_mi, phrases_tfidf, phrases_freq, phrases_yake, phrases_scake, phrases_trank, phrases_ent_nc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f54399830bbbc072644b83a18bcca8782c4daf93d62544fb85b1f9757394fef"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('gabby-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
